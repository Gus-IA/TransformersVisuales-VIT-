# Vision Transformer (ViT) desde cero + ViT preentrenado con timm

Este repositorio contiene una implementaci√≥n **desde cero** de un Vision Transformer (ViT) usando PyTorch, junto con un segundo modelo basado en la implementaci√≥n oficial de `timm`.  
Todo el entrenamiento se realiza sobre el dataset **MNIST**, cargado desde `fetch_openml`.

El c√≥digo muestra:

- C√≥mo cargar MNIST manualmente desde OpenML.
- C√≥mo crear un `LightningDataModule`.
- C√≥mo preparar las im√°genes correctamente para modelos de visi√≥n (formato **(B, 1, 28, 28)**).
- Implementaci√≥n propia de:
  - Patch Embedding con convoluciones.
  - Multi-Head Self Attention.
  - Transformer Encoder Blocks.
  - Clasificador basado en el token `[CLS]`.
- C√≥mo entrenar un modelo con PyTorch Lightning.
- Comparaci√≥n con el VisionTransformer de `timm`.
- Visualizaci√≥n y predicci√≥n sobre im√°genes reales.

---

üß© Requisitos

Antes de ejecutar el script, instala las dependencias:

pip install -r requirements.txt

üßë‚Äçüíª Autor

Desarrollado por Gus como parte de su aprendizaje en Python e IA.
